# ðŸ§  Local Chatbot using Ollama + Flask + Docker

This project demonstrates how to build a **local AI chatbot** using:

- **Ollama** (LLaMA 3 model)
- **Python Flask backend**
- **Docker** container
- **Simple HTML UI**

---

## ðŸš€ Features

- Runs fully offline
- Uses Ollama for local LLaMA inference
- Dockerized for easy deployment
- Simple web UI

---

## ðŸ“¦ Installation

### 1. Install Ollama
Download: https://ollama.com  
Then pull a model:

```bash
ollama pull llama3
